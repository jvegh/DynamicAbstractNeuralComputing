<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>§ 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18</title>
<!--Generated on Sun Feb 23 11:22:34 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on February 23, 2025.-->

<link rel="shortcut icon" href="../../../favicon.ico" type="image/png">
<link rel="stylesheet" href="../../../LaTeXML.css" type="text/css">
<link rel="stylesheet" href="../../../ltx-book.css" type="text/css">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link rel="stylesheet" href="../../../latexmldoc.css" type="text/css">
<script src="../../../LaTeXML-maybeMathjax.js"></script>
<link rel="up" href="index.html" title="§ 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="up up" href="../index.html" title="Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="up up up" href="../../index.html" title="Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="start" href="../../index.html" title="Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="prev" href="sec_Single-ElectricStages.html" title="§ 1.4.4 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="next" href="../../ch_Physics/index.html" title="Chapter 2 Physics for neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="subsection" href="sec_Single_AbstractElectricOperation.html" title="§ 1.4.1 Abstract electric operation ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="subsection" href="sec_Single-Operation.html" title="§ 1.4.2 Operating principles ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="subsection" href="sec_Single-Components.html" title="§ 1.4.3 Components ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="subsection" href="sec_Single-ElectricStages.html" title="§ 1.4.4 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="section" href="../sec_Single-Introduction/index.html" title="§ 1.1 Introduction ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="section" href="../sec_Single-ClassicVsModern/index.html" title="§ 1.2 Classic vs modern approach ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="section" href="../sec_SINGLE_ABSTRACT_NEURON/index.html" title="§ 1.3 Abstract modeling ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="section" href="index.html" title="§ 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="chapter" href="../../ch_Foreword/index.html" title="Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="chapter" href="../../ch_QuickStart/index.html" title="Quick Start ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="chapter" href="../index.html" title="Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="chapter" href="../../ch_Physics/index.html" title="Chapter 2 Physics for neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="chapter" href="../../ch_Physiology/index.html" title="Chapter 3 Abstract neurophysiology ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="chapter" href="../../ch_Computing/index.html" title="Chapter 4 Neural computing ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="chapter" href="../../ch_Information/index.html" title="Chapter 5 Neural information ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="chapter" href="../../ch_Multiple/index.html" title="Chapter 6 Multiple neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="chapter" href="../../ch_Intelligence/index.html" title="Chapter 7 Intelligence ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="chapter" href="../../ch_Simulation/index.html" title="Chapter 8 Neural simulator ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="bibliography" href="../../bib.html" title="Bibliography ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<link rel="index" href="../../idx.html" title="Index ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18">
<meta name="keywords" lang="en" content="Shannon, Claude, entropy, information, local time, neural, refractory period, slow current, synaptic gate, synchrony signal, time window, time-space, voltage gradient">
</head>
<body>
<nav class="ltx_page_navbar">
<div class="ltx_para">
<img src="../graphics/BrainElectronics.png" class="ltx_graphics ltx_img_landscape" width="252" height="142" alt="[Uncaptioned image]">
<p class="ltx_p">Dynamic Abstract Neural Computing
<br class="ltx_break">with Electronic Simulation
<br class="ltx_break">(DANCES) Version <em class="ltx_emph ltx_font_italic">0.0.18</em>
<br class="ltx_break">@February 23, 2025</p>
</div>
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_chapter"><a href="../../ch_Foreword/index.html" title="In Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title">Foreword</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter"><a href="../../ch_QuickStart/index.html" title="In Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title">Quick Start</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter">
<a href="../index.html" title="In Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Single neurons</span></a>
<ol class="ltx_toclist ltx_toclist_chapter">
<li class="ltx_tocentry ltx_tocentry_section"><a href="../sec_Single-Introduction/index.html" title="In Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="../sec_Single-ClassicVsModern/index.html" title="In Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.2 </span>Classic vs modern approach</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="../sec_SINGLE_ABSTRACT_NEURON/index.html" title="In Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.3 </span>Abstract modeling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="index.html" title="In Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.4 </span>Abstract operation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="sec_Single_AbstractElectricOperation.html" title="In § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.4.1 </span>Electric operation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="sec_Single-Operation.html" title="In § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.4.2 </span>Operating principles</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="sec_Single-Components.html" title="In § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.4.3 </span>Components</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="sec_Single-ElectricStages.html" title="In § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.4.4 </span>Stages</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection ltx_ref_self">
<span class="ltx_ref ltx_ref_self"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.4.5 </span>Stages and processes</span></span>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a href="#sec:Single-ConceptualOperation" title="In § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title">Conceptual operation</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a href="#sec:Single-OperationComputing" title="In Conceptual operation ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title">Stage ’Computing’</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a href="#sec:Single-OperationDelivering" title="In Conceptual operation ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title">Stage ’Delivering’</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a href="#sec:Single-OperationRelaxing" title="In Conceptual operation ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title">Stage ’Relaxing’</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a href="#sec:Single_AP_Synaptic" title="In Conceptual operation ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title">Synaptic control</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a href="#sec:Single-OperationClassicStages" title="In Conceptual operation ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title">Classic stages</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a href="#sec:Single-OperationInformation" title="In Conceptual operation ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title">Delivering information</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a href="#sec:Single-OperationSynchronization" title="In Conceptual operation ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title">Synchronization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a href="#sec:Single-OperationLearning" title="In Conceptual operation ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title">Learning</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a href="#sec:Single-ActionPotential" title="In § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title">Action Potential (AP)</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a href="#sec:Single_SendingAP" title="In Action Potential (AP) ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title">Sending AP</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a href="#sec:Single_ReceivingAP" title="In Action Potential (AP) ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title">Receiving AP</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#subsec:Single-PSP" title="In § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title">Post-synaptic potentials (PSP)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#sec:Single-ImplicationsComputing" title="In § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title">Implications for computing</span></a></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_chapter"><a href="../../ch_Physics/index.html" title="In Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Physics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter"><a href="../../ch_Physiology/index.html" title="In Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Physiology</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter"><a href="../../ch_Computing/index.html" title="In Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Computing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter"><a href="../../ch_Information/index.html" title="In Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Information</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter"><a href="../../ch_Multiple/index.html" title="In Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Multiple neurons</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter"><a href="../../ch_Intelligence/index.html" title="In Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Intelligence</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter"><a href="../../ch_Simulation/index.html" title="In Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Simulation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_bibliography"><a href="../../bib.html" title="In Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title">Bibliography</span></a></li>
<li class="ltx_tocentry ltx_tocentry_index"><a href="../../idx.html" title="In Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_title">Index</span></a></li>
</ol></nav>
<div class="ltx_para">
<p class="ltx_p"><a href="../simulator/ToIssue.html" title="" class="ltx_ref ltx_href">Report issue</a>
<a href="../manual.pdf" title="" class="ltx_ref ltx_href">Manual in .PDF form</a>
<a href="../simulator/index.html" title="" class="ltx_ref ltx_href">Simulator</a>
<a href="../simulator/ToCode.html" title="" class="ltx_ref ltx_href">Code</a>
<img src="../graphics/NeuronAndBrain.jpg" class="ltx_graphics ltx_img_square" width="252" height="252" alt="[Uncaptioned image]">
</p>
</div></nav>
<div class="ltx_page_main">
<header class="ltx_page_header">
<div class="ltx_align_center">
<a href="index.html" title="In Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref" rel="up"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.4 </span>Abstract operation</span></a><a href="sec_Single-ElectricStages.html" title="In § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref" rel="prev"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.4.4 </span>Stages</span></a><a href="../../ch_Physics/index.html" title="In Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref" rel="next"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Physics</span></a>
</div></header>
<div class="ltx_page_content">
<section class="ltx_subsection ltx_authors_1line">
<h1 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">§ 1.4.5 </span>Stages and processes</h1>

<div id="p1" class="ltx_para">
<p class="ltx_p">Living organisms change from moment to
moment along their internal laws
and we can study them at different abstraction levels. ”Despite the extraordinary diversity and complexity of neuronal morphology and synaptic connectivity,
<span class="ltx_text ltx_font_italic">the nervous systems adopts a number of
basic principles</span>”. <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../bib.html#bib55" title="" class="ltx_ref">55</a>]</cite> Although we will discuss
their internal operation in terms of particular processes (the actual level depends on the process),
here we classify the obvious results of observations according to the principles
the foreword to this chapter mentions: how nature implements those ”basic rules”
by more simple <span class="ltx_text ltx_font_italic">processes</span> and <span class="ltx_text ltx_font_italic">states</span> (which we can describe by using
ordinary or extraordinary laws) and which <span class="ltx_text ltx_font_italic">events</span> it provides for the observer
(which we can use for staging those very complex ”signs of life”).</p>
</div>
<div id="p2" class="ltx_para">
<p class="ltx_p">Fig. <a href="#fig:NeuronStateMachine" title="Figure 1.4 ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.4</span></a> illustrates our abstract view of a neuron,
in this case as a ”state machine”.
Notice that the double circles are <span class="ltx_text ltx_font_italic">stages</span> (<span class="ltx_text ltx_font_italic">states</span> with event-defined periods) connected
by bended arrows representing <span class="ltx_text ltx_font_italic">instant stage transitions</span>, while at some other abstraction level we consider them as <span class="ltx_text ltx_font_italic">processes</span> having a temporal course
with their own <span class="ltx_text ltx_font_italic">event</span> handling. Fundamentally, the system is circulating along the blue pathway, and maintains its state by using
the black loops, but sometimes it takes the less common red pathways.
It reveives its inputs cooperatively
(controls the accepted amount of its external inputs from the upstream neurons by gating them by regulating a stage variable), furthermore
it actively communicates <span class="ltx_text ltx_font_italic">the time of its state change</span> (that is: <span class="ltx_text ltx_font_italic">not its state</span> as assumed in the so called neural information theory) toward the downstream neurons in a process
parallel with its mentioned activity.</p>
</div>
<div id="p3" class="ltx_para">
<p class="ltx_p">Initially, a neuron is in stage ”Relaxing” which is the ground state of its operation.
(We also introduce a ”Sleeping” or ”Standby” helper stage, which can be imagined
as a low-power mode in electronical or state maintenance mode of biological computing; or ”creating the neuron” in biology; a ”no payload activity” stage.) The stage transition from ”Sleeping” also <span class="ltx_text ltx_font_italic">resets the internal stage variable</span> membrane potential (to the value of the resting potential).
In biology, a ”leaking” background activity takes place: it changes (among others) the stage variable towards the system’s ”no activity” value.</p>
</div>
<figure id="fig:NeuronStateMachine" class="ltx_figure"><object type="image/svg+xml" data="fig/NeuronStateMachineSimple.svg" id="Ch1.F4.g1" class="ltx_graphics ltx_img_square" width="389" height="381"></object>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1.4: </span>The model of neuron as an abstract state machine</figcaption>
</figure>
<div id="p4" class="ltx_para">
<p class="ltx_p">An event (in form of a pulse of slow ions) arriving from the environment acts as a ”look at me” signal

and the system passes to ”Computing” stage: an excitation begins.
The external signal
acts as triggering a stage change and, simultaneously, contributes to the value of the internal stage variable (membrane voltage).
During normal operation, when the stage variable reaches the critial value (the threshold potential),
the system generates an event: passes to stage ”Delivering” and ”flushes” the collected charge.
In that stage, it starts to deliver a signal toward the environment
(to the other neurons connected to its axon) and after a fixed period, passes to stage ”Relaxing”,
without resetting the stage variable. From this event on, it is again in stage
”Relaxing”, where the ”leaking” and the input pulses from the upstream neurons contribute to its
stage variable. Process ”Delivering” operates an independent subsystem (”Firing”): happens simultaneously with
process of ”Relaxing” which, after some time, usually passes to the next ”Computing”.
Notice that <span class="ltx_text ltx_font_bold ltx_font_italic">the stages ”Computing” and ”Delivering” mutually block
each other and the I/O operations happen in parallel with them</span>. They have temporal lengths, and they must follow in the well-defined order (a ”proper sequencing”) ”Computing”<math id="p4.m1" class="ltx_Math" alttext="\Rightarrow" display="inline"><mo stretchy="false">⇒</mo></math> ”Delivering”<math id="p4.m2" class="ltx_Math" alttext="\Rightarrow" display="inline"><mo stretchy="false">⇒</mo></math>”Relaxing” Theoretically, <span class="ltx_text ltx_font_italic">a three-state system is needed to define the direction of time</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../bib.html#bib66" title="" class="ltx_ref">66</a>]</cite>; a fundamental issue for quantum-based computing. In electronical computing we can introduce this as ”up” edge and ”down” edge, with a ”hold” stage between. In electronical computing we can introduce this as ”up” edge and ”down” edge, with a ”hold” stage between. A charge-up process must always happen before discharging. Stage ”Delivering” has a fixed period, stage ”Computing” has a variable period (depends mainly on the upstream neurons), and the total length of the computing period equals their sum. The (physiologically defined) length of the ”Delivering” period limits neuron’s firing rate; the length of ”Computing” is usually much shorter. In any stage, a ”leaking current” changing the stage variable is present; <span class="ltx_text ltx_font_bold ltx_font_italic">the continuous change (the presence of a voltage gradient) has a fundamental importance for a biological computing system</span>. 
This current is proportional to the stage variable (membrane current); it is <span class="ltx_text ltx_font_bold ltx_font_italic">not</span> identical with the fixed-size ”leaking current” assumed in the Hodgkin-Huxley model <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../bib.html#bib47" title="" class="ltx_ref">47</a>]</cite>.
The event which is issued when stage ”Computing” ends and ”Delivering” begins, separates two physically different operating modes: inputting payload signals for computing
and inputting ”servo” ions for transmitting
(signal transmission to fellow neurons begins and happens in parallel
with further computation(s)).</p>
</div>
<div id="p5" class="ltx_para">
<p class="ltx_p">There are two more possible stage transitions from the stage ”Computing”.
First, the stage variable (due to ”leaking”) may approach its initial value (the resting potential) and the system passes to stage ”Relaxing”; in this case we consider that the excitation ”Failed”.
This happens when leaking is more intense than the input current pulses (the input firing rate is too low or a random firing event started the computing).
Second, an external pulse may have the effect to force the system (independently from the value of the stage variable) to pass instantly to stage ”Delivering”, and after that, to ”Relaxing”. (When several neurons share that input signal,
they will go to ”Relaxing” at the same time: they get synchronized; a simple way of synchronizing low-precision asynchronous oscillators.)</p>
</div>
<div id="p6" class="ltx_para">
<p class="ltx_p">Anyhow: a neuron operates in cooperation with in its environment (the fellow neurons, with outputs distributed in space and time).
It receives multiple inputs at different times (at different offset times from the different upstream neurons) and in different stages.
In stage ”Computing”, the synaptic inputs are open, while
in stage ”Delivering”, the synaptic inputs are closed (the input is ineffective).
It produces multiple outputs (in the sense that the signal may branch along its path), in form of a signal with temporal course.</p>
</div>
<section id="sec:Single-ConceptualOperation" class="ltx_subsubsection">
<h2 class="ltx_title ltx_title_subsubsection">Conceptual operation</h2>

<div id="SSSx1.p1" class="ltx_para">
<p class="ltx_p">With reference to Fig. <a href="#fig:AP_Conceptual" title="Figure 1.5 ‣ Action Potential (AP) ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.5</span></a>, we subdivide neuron’s operation
to three stages (green, red, and blue sections of the broken diagram line), in line with the state machine in Fig. <a href="#fig:NeuronStateMachine" title="Figure 1.4 ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.4</span></a>.
We start in stage ’Relaxing’ (it is a steady-state,
with the membrane’s voltage at its resting value). Everything is balanced,
the synaptic inputs are enabled.
No currents flow (neither input nor output), since all component have the same potential, there is no driving force for an output current.</p>
</div>
<div id="SSSx1.p2" class="ltx_para">
<p class="ltx_p">The neuron has a stage variable (the membrane potential) and a regulatory
threshold value. There exists a threshold for <span class="ltx_text ltx_font_italic">voltage gradient</span> instead of the <span class="ltx_text ltx_font_italic">membrane’s voltage</span> itself
(the voltage gradient provides a ’driving force’).

As we detail in section <a href="../../ch_Physics/sec_Physics-segmented/sec_Demon-in-the-membrane.html#sec:Electrodiffusion_VoltageSensing" title="Voltage sensing ‣ § 2.7.5 Demon in the membrane ‣ § 2.7 Segmented electrolytes ‣ Chapter 2 Physics for neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.7.5</span></a>, the voltage sensing is based on voltage gradient sensing, which phenomenon correlates with the value of membrane’s voltage.
Given that physiological measurements (such as clamping) suppress the gradient, and only the voltage is measured in a
’freezed’ state, this difference has remained hidden. Crossing the membrane’s voltage threshold value upward and downward causes a
stage transition from ”Computing” to ”Delivering” and from ”Delivering”
to ”Relaxing”, respectively. Another role of that regulatory value is
to open/close the input synapses. Furthermore, when the value exceeds
the threshold, an intense current starts to charge up the condenser,
that later discharges.
We show that, although the change correlates with the value
of membrane’s voltage, the neuron’s membrane actually senses the voltage gradient.</p>
</div>
<div id="SSSx1.p3" class="ltx_para">
<p class="ltx_p">Given that the neuron’s operation resembles
an <math id="SSSx1.p3.m1" class="ltx_Math" alttext="RC" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mi>C</mi></mrow></math> oscillator, the capacitive current of the condenser
changes its direction, leading to changing the potential relative
to the charge-up potential value to a value of opposite sign.
The time constant of the <math id="SSSx1.p3.m2" class="ltx_Math" alttext="RC" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mi>C</mi></mrow></math> oscillator
is set so that the rushed-in current generates a nearly critically damped
oscillation (with a damping parameter about <math id="SSSx1.p3.m3" class="ltx_Math" alttext="\zeta=0.35" display="inline"><mrow><mi>ζ</mi><mo>=</mo><mn>0.35</mn></mrow></math>).</p>
</div>
<div id="SSSx1.p4" class="ltx_para">
<p class="ltx_p">Notice that all these processes happen with well-defined speeds,
i.e., the different stages have well-defined temporal lengths. The length of period ”Delivering” is fixed (defined by physiological parameters),
the length of ”Computing” depends on the activity of the upstream
neurons (furthermore, on the gating due to the membrane’s voltage).
Due to the finite speed, we discuss all operations in

neuron’s own ”local time”.</p>
</div>
<div id="SSSx1.p5" class="ltx_para">
<p class="ltx_p">When the membrane’s voltage decreases below the threshold value,
the axonal inputs are re-opened, that may mean an instant passing
to stage ”Computing” again.
The current stops only when the charge on the membrane disappears (the driving force terminates),
so the current may change continuously, changing the voltage on the
circuit’s output.
The time of the end of operation is ill-defined, and so is the
value of the membrane’s voltage at the time when the next axonal input arrives. <span class="ltx_text ltx_font_italic">The residual potential acts as a (time-dependent) memory</span>,
with about a <math id="SSSx1.p5.m1" class="ltx_Math" alttext="msec" display="inline"><mrow><mi>m</mi><mo>⁢</mo><mi>s</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>c</mi></mrow></math> lifetime; see Fig. <a href="#fig:AP_Conceptual" title="Figure 1.5 ‣ Action Potential (AP) ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.5</span></a>.</p>
</div>
<section id="sec:Single-OperationComputing" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Stage ’Computing’</h3>

<div id="SSSx1.Px1.p1" class="ltx_para">
<p class="ltx_p">The neuron receives its inputs as ’Axonal inputs’. For the first input in stage ’Relaxing’,
the neuron enters stage ’Computing’.
The time of this event is the base time used for calculating the neuron’s ”local time”.

Notice that producing the result is a cooperation
between the neuron and its upstream neurons (the neuron gates its input currents). One of the upstream neurons
opens computing, and the receiving neuron terminates it.</p>
</div>
</section>
<section id="sec:Single-OperationDelivering" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Stage ’Delivering’</h3>

<div id="SSSx1.Px2.p1" class="ltx_para">
<p class="ltx_p">In this stage,
the result is ready: the time between the arrival of the first
synaptic input and reaching the membrane’s threshold voltage is measured.
No more input is desirable, so the neuron closes its input synapses.
Simultanously, the neuron starts it ”servo” mechanism: it opens its ion channels
and an intense ion current starts to charge the membrane.
It is an ’instant’ current.
The voltage on the membrane quickly rises, and it takes a short time
until its peak voltage reached.
Given that the charge-up current is instant and the increased
membrane voltage drives an outward current, the membrane voltage
gradually decays.
When the voltage drops below the threshold voltage, the neuron re-opens its synaptic inputs and passes to stage ”Relaxing”: it is ready for the next operation. The signal transmission to downstream neurons
happens in parallel with the recent ”Delivering” stage and
the next ”Relaxing” and maybe ”Computing” stages.</p>
</div>
</section>
<section id="sec:Single-OperationRelaxing" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Stage ’Relaxing’</h3>

<div id="SSSx1.Px3.p1" class="ltx_para">
<p class="ltx_p">In this stage,
the neuron re-opens its synaptic gates. Recall that the ion channels
used for generating an intense membrane current
are already closed. The neuron passes to stage ’Relaxing’ and is ready for a new computation:
the previous result is under delivering (parallelly, independently),
the axonal inputs are open again.
However, the membrane’s potential at this point may differ from the
resting potential. A new computation begins
(the neuron passes to the stage ”Computing”)
when a new axonal input arrives. Given that the computation is analog, a current flows through the AIS, and the result is the length of the period to reach
the threshold value, the
membrane voltage plays the role of an accumulator (with a time-dependent content): a non-zero initial value acts as a short-time memory in the next computing cycle.
The local time is reset when a new computating cycle begins, but not when eventually the resting potential reached.
</p>
</div>
</section>
<section id="sec:Single_AP_Synaptic" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Synaptic control</h3>

<div id="SSSx1.Px4.p1" class="ltx_para">
<p class="ltx_p">As discussed, controling the operation of its synapses is a
fundamental part of neuronal operation. It is
a kind of gating and implements an ’autonomous cooperation’ with
the upstream neurons. The neuron’s gating uses
a ’downhill method’ for gating: while the membrane’s potential
is above of that of the axonal arbor, the charges cannot enter the membrane.
As soon as the membrane’s voltage exceeds the threshold voltage, the synaptic inputs stop, and restart only when the voltage drops below of that threshold.
The synaptic gating makes interpreting neural information and entropy, as we discuss it in <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../bib.html#bib119" title="" class="ltx_ref">119</a>]</cite> and chapter <a href="../../ch_Information/index.html" title="Chapter 5 Neural information ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, at least hard.



</p>
</div>
</section>
<section id="sec:Single-OperationClassicStages" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Classic stages</h3>

<div id="SSSx1.Px5.p1" class="ltx_para">
<p class="ltx_p">We can map our ’modern’ stages to those ’classic’ stages and we can see
why defining the length of the Action Potential
is problematic.
The effect of slow current affects the apparent boundary between our
”Delivering” stage and ”Relaxing” stages.
Classical physiology sees the difference and distinguishes ’absolute’ and
’relative’ refractory periods with a smeared boundary between. Furthermore,
it defines the length of the spike with some characteristic point,
such as reaching the resting value for the first or second time, or
reaching the maximum polarization/hyperpolarization. Our derivation of the stages (see Fig. <a href="#fig:AP_Conceptual" title="Figure 1.5 ‣ Action Potential (AP) ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.5</span></a>) defines clear-cut breakpoints between them.</p>
</div>
<div id="SSSx1.Px5.p2" class="ltx_para">
<p class="ltx_p">We can define the length of the spike as the sum of the variable-size length of periods ”Computing” and fixed-size period ”Delivering”. The ”absolute refractory”
period is defined as the period while the neuron membrane’s voltage keeps
the gates of the synaptic inputs closed (the value of membrane voltage is above their threshold). That period is apparently extended
(and interpreted as a ”relative refractory” period)
by the period when although the gating is re-enabled, but the slow current did not
yet arrive to the
AIS
where it contributes to the measured
AP, see Fig. <a href="#fig:AP_Conceptual" title="Figure 1.5 ‣ Action Potential (AP) ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.5</span></a>. <span class="ltx_text ltx_font_italic">Only one refractory period exists,
plus the effect of the slow current.</span>
</p>
</div>
</section>
<section id="sec:Single-OperationInformation" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Delivering information</h3>

<div id="SSSx1.Px6.p1" class="ltx_para">
<p class="ltx_p">As follows from our interpretation, the appearance of a huge voltage gradient
(evoked by the sudden rush-in current) represents the output
information the neuron delivers, and also the input information
it receives from its upstream neurons through its synapses.

Given that the input currents delivered by the spikes
are gated by the neuron, the information that can be
accounted in the computation must be in the front side of spikes. (The back side is mainly needed for restoring the resting potential.)</p>
</div>
<div id="SSSx1.Px6.p2" class="ltx_para">
<p class="ltx_p">The front side (in the form of a sudden step in the value of the voltage gradient) delivers an extremely precise timing information about at what time the rush-in event in the sender happened, explaining the half-understood experience <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../bib.html#bib79" title="" class="ltx_ref">79</a>]</cite> why
”the timing of spikes is important with a
precision roughly two orders of magnitude greater than the temporal
dynamics of the stimulus”. If exceeding the threshold
is the consequence of the charge arriving from a single
upstream neuron, the neuron simply transmits the timing information it received. If several smaller gradients
are summed (and recall that the component gradients decay with
time after their arrival) for reaching the gradient,
then their information content is weighted.</p>
</div>
</section>
<section id="sec:Single-OperationSynchronization" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Synchronization</h3>

<div id="SSSx1.Px7.p1" class="ltx_para">
<p class="ltx_p">Given that the voltage gradient is the pace of temporal change,
a faster rush-in current in the upstream neuron (seen as
a steeper slope <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../bib.html#bib67" title="" class="ltx_ref">67</a>]</cite>)
can evoke firing, independently from the membrane’s voltage. 
This observation, alone, underpins
that exceeding a <span class="ltx_text ltx_font_italic">voltage gradient threshold</span> (instead of
a <span class="ltx_text ltx_font_italic">voltage threshold</span>)
leads to firing.
Receiving a synchrony signal does not set the ”local time”

to zero; instead, it forces an instant firing. After firing,
the first synaptic input sets the time base as we have discussed it above.</p>
</div>
<div id="SSSx1.Px7.p2" class="ltx_para">
<p class="ltx_p">It is interesting to note that, according to Shannon,


a single spike does not carry information, given that the shape of the spikes are identical, only its time can deliver information. And, yet,
a single spike can carry the information that a new collective operation (of neurassemblies) begins and the participating neuron’s operation must synchronize their ”local time” to a remote basetime. In the sense of time-space, the signal resets the time base of all receiver neurons to zero. That is, all their synchronized upstream neurons will reset their timebase to that synchrony signal. Consequently, the neuron will receive its input spikes on a relatively well-defined scale, despite that the sender neurons send their spikes at different absolute times; by automatically ”calculating” and applying
the needed offset time.
The neuron’s frequency stability is low, so the synchrony signal (the base frequencies) must be repeated relatively frequently for the system’s stable operation.
Of course, the neuron does not know the absolute time.



The local time’s starting time <math id="SSSx1.Px7.p2.m1" class="ltx_Math" alttext="t_{o}" display="inline"><msub><mi>t</mi><mi>o</mi></msub></math>
is the time when the first synaptic input arrives and its range of interpretation ends when a new computation starts or when
the membrane’s potential goes back to its resting value.</p>
</div>
</section>
<section id="sec:Single-OperationLearning" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Learning</h3>

<div id="SSSx1.Px8.p1" class="ltx_para">
<p class="ltx_p">It might also happen that (also depending on the residual
membrane voltage) the outgoing spike’s delivering begins
immediately after last spike arrives.
Given that the rising edge delivers the important timing information, and the voltage gradients contributions
received before the last spike somewhat faded in the meantime,
one can understand Hebb’s observation in terms of learning: the last spike (before firing) contributes more than the ones
received earlier.
</p>
</div>
</section>
</section>
<section id="sec:Single-ActionPotential" class="ltx_subsubsection">
<h2 class="ltx_title ltx_title_subsubsection">Action Potential (AP)</h2>

<div id="SSSx2.p1" class="ltx_para">
<p class="ltx_p">With putting together the operating stages (as we have mentioned: in a well-defined order), one receives the
characteristic process of neuronal operation (an operating cycle): the stage variable changes in a well-defined pace in the function of the local time. As depicted in Fig. <a href="#fig:AP_Conceptual" title="Figure 1.5 ‣ Action Potential (AP) ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.5</span></a>, the stage variable can be well observed inside the cell, furthermore, it has a well-measurable effect outside the cell. The notion
of neuronal operation is the current pulse (called ’Action Potential’) has a central role in neural operation. Here we discuss concepts of its production, while its sending and receiving in the next sections. The stages we have discussed previously are are color-coded in the diagram line.
The stage variable in the ”Computing” stage is observable
only inside the cell. After the beginning of stage ”Delivering”, the characteristics of the emitted charge pulse are well observable also outside the cell. The figures on the axes are approximately correct: the measurable voltage change is up to several dozens of millivolts, and the time scale
is up to several milliseconds.</p>
</div>
<figure id="fig:AP_Conceptual" class="ltx_figure"><object type="image/svg+xml" data="fig/AP_Schematic.svg" id="Ch1.F5.g1" class="ltx_graphics ltx_img_landscape" width="598" height="427"></object>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1.5: </span>The conceptual graph of the action potential </figcaption>
</figure>
<div id="SSSx2.p2" class="ltx_para">
<p class="ltx_p">As we discussed in section <a href="#sec:Single-ConceptualOperation" title="Conceptual operation ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.4.5</span></a>,
at the beginning of an operating cycle, synapses are open and some input pulses (gradient steps)
increase the membrane’s potential <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../bib.html#bib58" title="" class="ltx_ref">58</a>, <a href="../../bib.html#bib60" title="" class="ltx_ref">60</a>]</cite> (the green section of the broken line).
After exceeding the membrane’s threshold voltage (the dotted orange line), the synapses’ gating mechanism closes the current inputs and
the membrane’s rush-in mechanism begins to work due to opening voltage-controlled ion channels
in the membrane’s wall. The effect extends over the surface in an
avalanche-like way <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../bib.html#bib11" title="" class="ltx_ref">11</a>]</cite>. The voltage increases
until all ion channels get opened. The ion channels close after a very short
period and the neuronal <math id="SSSx2.p2.m1" class="ltx_Math" alttext="RC" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mi>C</mi></mrow></math> circuit continues its operation with discharging the condenser (the red section of the broken line). Given that the condenser stores part of the received charge,
the capacitive current decreases and later reverses and reverts also the resulting current (and, consequently, the measurable voltage; this effect is observed as the membrane gets hyperpolarized).
In this period (the blue section of the broken line) the
synapses are open again and the received synaptic input gradients
contribute again to the membrane’s voltage. That is, a new cycle
(this time starting with a potential differring from the resting value)
can start and that residual potential acts as a memory
(the details of the electrical processes are discussed in section <a href="../../ch_Physics/sec_Physics-Electricity/sec_PHYSICS_MEASURINGOSCILLATOR.html" title="§ 2.8.4 Oscillator ‣ § 2.8 Electricity in biology ‣ Chapter 2 Physics for neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.8.4</span></a>).
Notice that all mentioned events are spatiotemporal; most noticably,
the arrival of the synaptic inputs to the synaptic terminal
following the absolute refractory period is much earlier than
they are observable as an increase in the potential value (measured at
the
AIS).
Also notice that there is no direct connection between the
input and output voltages: the <math id="SSSx2.p2.m2" class="ltx_Math" alttext="RC" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mi>C</mi></mrow></math> circuit fundamentally
changes the neuronal output.</p>
</div>
<section id="sec:Single_SendingAP" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Sending AP</h3>

<div id="SSSx2.Px1.p1" class="ltx_para">
<p class="ltx_p">Sending
AP
begins when the membrane’s potential exceeds the threshold
and terminates when it drops below the threshold. The time of
the stage ”Delivering” is entirely determined by the parameters
<math id="SSSx2.Px1.p1.m1" class="ltx_Math" alttext="C" display="inline"><mi>C</mi></math> and <math id="SSSx2.Px1.p1.m2" class="ltx_Math" alttext="R" display="inline"><mi>R</mi></math> of the neuronal oscillator, so all outgoing spikes have the same shape. However,
depending of the time of the previous spike (or, more precisely,
the value of the membrane’s potential at the moment of the start of ”Delivering”), the shape may be apparently different.
The measurable potential is the sum of the ”tail” of the
previous spike plus the front of ”this” spike; and both of them have
their temporal course (the currents that evoke those voltages are slow).
The effect of gating can be observed with a time delay at the
AIS (the slow current entering through the synaptic terminals needs time to reach the AIS), and the value of that delay depends on the geometry of the neuron,
mainly on the position of the synaptic terminal.
On its ”local time” scale, the AP starts when

the neuron’s rush-in current starts (due to exceeding
the threshold for the voltage gradient).</p>
</div>
</section>
<section id="sec:Single_ReceivingAP" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Receiving AP</h3>

<div id="SSSx2.Px2.p1" class="ltx_para">
<p class="ltx_p">The native input arrives through the synaptic terminals, at the
time determined by the upstream neuron (in the sense that
at what absolute time it sends the spike and how long the spike travels).
The time window of the ”Computing” period opens when the first
input arrives and so the further inputs arrive at a later time.
The time window ends when the membrane’s voltage exceeds its threshold.
Given that the computing time is in the order of <math id="SSSx2.Px2.p1.m1" class="ltx_Math" alttext="0.1\ ms" display="inline"><mrow><mn>0.1</mn><mo lspace="0.500em">⁢</mo><mi>m</mi><mo>⁢</mo><mi>s</mi></mrow></math>
and the total length of an
AP
is in the order of up to <math id="SSSx2.Px2.p1.m2" class="ltx_Math" alttext="10\ ms" display="inline"><mrow><mn>10</mn><mo lspace="0.500em">⁢</mo><mi>m</mi><mo>⁢</mo><mi>s</mi></mrow></math>,
only the first temporal part of the received spike can be processed and can contribute
to the result: as the membrane’s potential increases, the neuron
closes its synapses. That means that the neurons coooperate with
their upstream neurons: the contributions to their membrane’s charge through their synapses change
even between the adjacent spikes. Even, the composition of the sum
may change, depending on in which order the input spikes arrive.</p>
</div>
</section>
</section>
<section id="subsec:Single-PSP" class="ltx_subsubsection">
<h2 class="ltx_title ltx_title_subsubsection">Post-synaptic potentials (PSP) </h2>

<div id="SSSx3.p1" class="ltx_para">
<p class="ltx_p">During regular neuronal operation, spikes arrive through synapses,
and their effect can also be measured as a
PSP. When a spike
(evoked by a single
AP, elicited by current injection in presynaptic
cells) <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../bib.html#bib72" title="" class="ltx_ref">72</a>]</cite> arrives at a synapse,
it can be represented that a (short pulse of) “slow” current arrives
through the axon. However, the inflow of the axonal current is “slow”,
and a “critical mass” of ions is needed to start a well-defined current
inflow into the membrane, so neuronal arborization <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../bib.html#bib39" title="" class="ltx_ref">39</a>]</cite>
takes place, forming an “ion buffer”.
If a current <math id="SSSx3.p1.m1" class="ltx_Math" alttext="I" display="inline"><mi>I</mi></math> arrives through the axon, when entering the arbor, the cross section <math id="SSSx3.p1.m2" class="ltx_Math" alttext="A" display="inline"><mi>A</mi></math> suddenly increases, so <math id="SSSx3.p1.m3" class="ltx_Math" alttext="v" display="inline"><mi>v</mi></math> suddenly decreases; see Eq.(<a href="../../ch_Physics/sec_Physics-Electricity/sec_Physics-Current.html#eq:DriftCurrent" title="In § 2.8.1 Current ‣ § 2.8 Electricity in biology ‣ Chapter 2 Physics for neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.27</span></a>). The arbor buffers the charge received in the spike.
The mechanism that the ion current ’takes away’ the ions does not work in the arbor. The ions can move under the voltage gradient resulting from the mutual repulsion and the current drain towards the membrane.<span class="ltx_text ltx_font_italic"> The drain current (into the membrane) is proportional to the voltage gradient
between the arbor and the membrane,

giving a natural explanation how the membrane’s potential controls synaptic contributions, furthermore why the potential increase in the ”relative refractory” period changes with the membrane’s potential.</span> For details, see section <a href="#sec:Single_AP_Synaptic" title="Synaptic control ‣ Conceptual operation ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.4.5</span></a> and Figure <a href="../../ch_Physiology/sec_Physiology-Experimental/sec_Axonal-charge-delivery.html#fig:MasonFig4" title="Figure 3.18 ‣ § 3.6.2 Axon ‣ § 3.6 Experimental evidence ‣ Chapter 3 Abstract neurophysiology ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.18</span></a>. Whether the buffer is filled or empty explains that
‘both sodium and
potassium conductances increase with a delay when the axon is depolarized
but fall with no appreciable inflexion when it is repolarized’ <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../bib.html#bib47" title="" class="ltx_ref">47</a>]</cite>.</p>
</div>
<div id="SSSx3.p2" class="ltx_para">
<p class="ltx_p">The arbor essentially (and anatomically) belongs to the
axon, but its functionality is also similar to that of the membrane. It <em class="ltx_emph ltx_font_italic">plays a vital role in the information processing in the brain</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../bib.html#bib42" title="" class="ltx_ref">42</a>]</cite>:
defines the crucial input parameter “time of arrival of a spike”, makes the intensity of synaptic inputs nearly independent from the shape of the spike (less depending on the presynaptic neuron; important for the cooperation); furthermore, links adjacent spikes, providing a neuronal memory.
The buffering effect may be seen as “making a hole in the membrane” <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../bib.html#bib60" title="" class="ltx_ref">60</a>]</cite>:
exceeding a critical mass (charge in the arbor) may start an intensive
current into the membrane and manifest in a sudden <math id="SSSx3.p2.m1" class="ltx_Math" alttext="\frac{d}{dt}V" display="inline"><mrow><mfrac><mi>d</mi><mrow><mi>d</mi><mo>⁢</mo><mi>t</mi></mrow></mfrac><mo>⁢</mo><mi>V</mi></mrow></math> change, see section <a href="../../ch_Physiology/sec_Physiology-DerivingActionPotential/sec_Physiology-VoltageTimeDerivative.html" title="§ 3.4.6 Voltage time derivative ‣ § 3.4 Action potential ‣ Chapter 3 Abstract neurophysiology ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4.6</span></a>. The shape of
PSP
also plays a vital role in
synchronizing neurassemblies <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../bib.html#bib17" title="" class="ltx_ref">17</a>, <a href="../../bib.html#bib67" title="" class="ltx_ref">67</a>]</cite>.</p>
</div>
<div id="SSSx3.p3" class="ltx_para">
<p class="ltx_p">The buffering changes the shape of the received
AP: it integrates the input axonal current and distorts the received
AP’s
shape toward a
PSP: there is no
AIS in the axon (no oscillator).
Most schematic figures
showing signal transmission from a presynaptic neuron to a postsynaptic neuron
miss the point that at the synapse, the
AP
appears as having
a different shape. Furthermore, they misidentify the temporal length of
AP essentially to
a period between the beginning of the charge-up to the end of reaching
the hyperpolarization peak voltage (comprising the ’Delivering’ stage and some part of ’Relaxing’).
Our discussion shows that the stage ’Computing’ (reaching the threshold potential) and ’Relaxing’ (<span class="ltx_text ltx_font_italic">the long tail
after hyperpolarization) are a vital part of
AP</span>. The former is the result of the neuronal computation and the latter (among others) provides
short-term neuronal memory for neuronal cooperation.</p>
</div>
<div id="SSSx3.p4" class="ltx_para">
<p class="ltx_p">The intense current from this buffer starts to charge the membrane
and discharge the arbor. We arrive back at the case we saw in the
case of a clamping where a ”slow”
axonal input current from the arbor arrived at the membrane at its
junction. It flows with its finite speed on the membrane’s surface,
while, at the same time, the newly created potential decays exponentially.
Initially, while the buffer is charging, the current
increases exponentially as the spike arrives, manifesting
in the observable
PSP.
We can validate our model-based hypothesis by fitting experimental
data; see section <a href="../../ch_Physiology/sec_Physiology-Experimental/index.html" title="§ 3.6 Experimental evidence ‣ Chapter 3 Abstract neurophysiology ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.6</span></a>.</p>
</div>
</section>
<section id="sec:Single-ImplicationsComputing" class="ltx_subsubsection">
<h2 class="ltx_title ltx_title_subsubsection">Implications for computing</h2>

<div id="SSSx4.p1" class="ltx_para">
<p class="ltx_p">Fig. <a href="#fig:AP_Conceptual" title="Figure 1.5 ‣ Action Potential (AP) ‣ § 1.4.5 Stages and processes ‣ § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.5</span></a> also reveals some secrets of the effective
biological computing.</p>
<ul id="Ch1.S4.I2" class="ltx_itemize">
<li id="Ch1.S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Ch1.S4.I2.i1.p1" class="ltx_para">
<p class="ltx_p">biology makes the ”weighted summing” of neuron’s synaptic inputs
simultaneously, in one single operation making multiplication and integration, furthermore selecting the time window and its effective synaptic inputs</p>
</div>
</li>
<li id="Ch1.S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Ch1.S4.I2.i2.p1" class="ltx_para">
<p class="ltx_p">the heavily used neuronal information ”is stored, as it should be, in every circuit” <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../bib.html#bib105" title="" class="ltx_ref">105</a>]</cite></p>
</div>
</li>
<li id="Ch1.S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Ch1.S4.I2.i3.p1" class="ltx_para">
<p class="ltx_p">”information stored
directly at a synapse can be retrieved directly” <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../bib.html#bib105" title="" class="ltx_ref">105</a>]</cite></p>
</div>
</li>
<li id="Ch1.S4.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Ch1.S4.I2.i4.p1" class="ltx_para">
<p class="ltx_p">part of the information (in ’volatile’ memory) is stored only
for the period when it might be needed (a real temporary cache)</p>
</div>
</li>
<li id="Ch1.S4.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Ch1.S4.I2.i5.p1" class="ltx_para">
<p class="ltx_p">”Computing” is much shorter than ”Delivering”</p>
</div>
</li>
<li id="Ch1.S4.I2.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Ch1.S4.I2.i6.p1" class="ltx_para">
<p class="ltx_p">asynchronous; the operation time varies (no pipelining)</p>
</div>
</li>
<li id="Ch1.S4.I2.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Ch1.S4.I2.i7.p1" class="ltx_para">
<p class="ltx_p">”Send only information that is needed, and send it as slowly as possible” <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../bib.html#bib105" title="" class="ltx_ref">105</a>]</cite></p>
</div>
</li>
<li id="Ch1.S4.I2.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Ch1.S4.I2.i8.p1" class="ltx_para">
<p class="ltx_p">using voltage temporal gradients enables transferring more information and functionality;
for example, synchronization <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../bib.html#bib67" title="" class="ltx_ref">67</a>]</cite></p>
</div>
</li>
<li id="Ch1.S4.I2.i9" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Ch1.S4.I2.i9.p1" class="ltx_para">
<p class="ltx_p">for simulation: there is no need to send and integrate spike shapes,
only <span class="ltx_text ltx_font_italic">the time of arrival/sending</span></p>
</div>
</li>
</ul>
</div>
</section>
</section>
</div>
<footer class="ltx_page_footer">
<div class="ltx_align_center">
<a href="sec_Single-ElectricStages.html" title="In § 1.4 Neuron’s abstract electric operation ‣ Chapter 1 Single neurons ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref" rel="prev"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.4.4 </span>Stages</span></a><a href="../../bib.html" title="In Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref" rel="bibliography"><span class="ltx_text ltx_ref_title">Bibliography</span></a><a href="../../idx.html" title="In Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref" rel="index"><span class="ltx_text ltx_ref_title">Index</span></a><a href="../../ch_Physics/index.html" title="In Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.0.18" class="ltx_ref" rel="next"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Physics</span></a>
</div>
<div class="ltx_page_logo">Generated  on Sun Feb 23 11:22:34 2025 by <a href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>
</body>
</html>
