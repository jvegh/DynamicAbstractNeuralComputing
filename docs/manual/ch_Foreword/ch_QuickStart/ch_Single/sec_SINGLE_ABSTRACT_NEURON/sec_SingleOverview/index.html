<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>§ 1.3.6 Stages and processes ‣ § 1.3 Abstract modeling ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0</title>
<!--Generated on Fri May 23 09:01:16 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on May 23, 2025.-->

<link rel="shortcut icon" href="../../../../../../favicon.ico" type="image/png">
<link rel="stylesheet" href="../../../../../../LaTeXML.css" type="text/css">
<link rel="stylesheet" href="../../../../../../ltx-book.css" type="text/css">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link rel="stylesheet" href="../../../../../../latexmldoc.css" type="text/css">
<script src="../../../../../../LaTeXML-maybeMathjax.js"></script>
<link rel="up" href="../index.html" title="§ 1.3 Abstract modeling ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="up up" href="../../index.html" title="Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="up up up" href="../../../index.html" title="Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="up up up up" href="../../../../index.html" title="Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="up up up up up" href="../../../../../index.html" title="Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="start" href="../../../../../index.html" title="Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="prev" href="../sec_SINGLE_ExistingModels/index.html" title="§ 1.3.5 Existing models ‣ § 1.3 Abstract modeling ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="next" href="../../Single-Overview/index.html" title="§ 1.4 Overview of the play ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="subsection" href="../sec_SINGLE_ModelTypes/index.html" title="§ 1.3.1 Model types ‣ § 1.3 Abstract modeling ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="subsection" href="../sec_SINGLE_DisciplinaryApproach/index.html" title="§ 1.3.2 Disciplinary approach ‣ § 1.3 Abstract modeling ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="subsection" href="../sec_Single-Operation/index.html" title="§ 1.3.3 Operating principles ‣ § 1.3 Abstract modeling ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="subsection" href="../sec_SINGLE_ABSTRACT_CREATING/index.html" title="§ 1.3.4 Creating the brain ‣ § 1.3 Abstract modeling ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="subsection" href="../sec_SINGLE_ExistingModels/index.html" title="§ 1.3.5 Existing models ‣ § 1.3 Abstract modeling ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="section" href="../../sec_Single-Introduction/index.html" title="§ 1.1 Introduction ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="section" href="../../sec_Single-ClassicVsModern/index.html" title="§ 1.2 Modeling approaches ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="section" href="../index.html" title="§ 1.3 Abstract modeling ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="section" href="../../Single-Overview/index.html" title="§ 1.4 Overview of the play ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="section" href="../../sec_Single-ImplicationsComputing/index.html" title="§ 1.5 Implications for computing ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="chapter" href="../../index.html" title="Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="chapter" href="../../../index.html" title="Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<link rel="chapter" href="../../../../index.html" title="Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0">
<meta name="keywords" lang="en" content="Shannon, Claude, depolarization, entropy, hyperpolarization, information, local time, neural, refractory period, slow current, synaptic gate, synchrony signal, time window, time-space, voltage gradient">
</head>
<body>
<div class="ltx_page_main">
<header class="ltx_page_header">
<div class="ltx_align_center">
<a href="../index.html" title="In Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0" class="ltx_ref" rel="up"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.3 </span>Abstract modeling</span></a><a href="../sec_SINGLE_ExistingModels/index.html" title="In § 1.3 Abstract modeling ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0" class="ltx_ref" rel="prev"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.3.5 </span>Existing models</span></a><a href="../../Single-Overview/index.html" title="In Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0" class="ltx_ref" rel="next"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.4 </span>Overview</span></a>
</div></header>
<div class="ltx_page_content">
<section class="ltx_subsection ltx_authors_1line">
<h1 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">§ 1.3.6 </span>Stages and processes</h1>

<div id="p1" class="ltx_para">
<p class="ltx_p">Living organisms change from moment to
moment along their internal laws
and we can study them at different abstraction levels. ”Despite the extraordinary diversity and complexity of neuronal morphology and synaptic connectivity,
<span class="ltx_text ltx_font_italic">the nervous systems adopts a number of
basic principles</span>”. <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../sec_Single-ImplicationsComputing/ch_Physics/sec_Physics-Spatiotemporal/ch_Physiology/sec_Physiology-Fallacies/sec_Physiology-FallaciesAPThresholds/ch_Computing/sec_Computing-ActionPotential/ch_Information/ch_Multiple/ch_Intelligence/sec_Information-Cognition/ch_Simulation/GTKWave_Simulator/bib.html#bib2" title="" class="ltx_ref">2</a>]</cite> Although we will discuss
their internal operation in terms of particular processes (the actual level depends on the process),
here we classify the obvious results of observations according to the principles
the foreword to this chapter mentions: how nature implements those ”basic rules”
by more simple <span class="ltx_text ltx_font_italic">processes</span> and <span class="ltx_text ltx_font_italic">states</span> (which we can describe by using
ordinary or extraordinary laws) and which <span class="ltx_text ltx_font_italic">events</span> it provides for the observer
(which we can use for staging those very complex ”signs of life”).</p>
</div>
<div id="p2" class="ltx_para">
<p class="ltx_p">Fig. <a href="#fig:NeuronStateMachine" title="Figure 1.1 ‣ § 1.3.6 Stages and processes ‣ § 1.3 Abstract modeling ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.1</span></a> illustrates our abstract view of a neuron,
in this case as a ”state machine”.
Notice that the double circles are <span class="ltx_text ltx_font_italic">stages</span> (<span class="ltx_text ltx_font_italic">states</span> with event-defined periods) connected
by bended arrows representing <span class="ltx_text ltx_font_italic">instant stage transitions</span>, while at some other abstraction level we consider them as <span class="ltx_text ltx_font_italic">processes</span> having a temporal course
with their own <span class="ltx_text ltx_font_italic">event</span> handling. Fundamentally, the system is circulating along the blue pathway, and maintains its state by using
the black loops, but sometimes it takes the less common red pathways.
It reveives its inputs cooperatively
(controls the accepted amount of its external inputs from the upstream neurons by gating them by regulating a stage variable), furthermore
it actively communicates <span class="ltx_text ltx_font_italic">the time of its state change</span> (that is: <span class="ltx_text ltx_font_italic">not its state</span> as assumed in the so called neural information theory) toward the downstream neurons in a process
parallel with its mentioned activity.</p>
</div>
<div id="p3" class="ltx_para">
<p class="ltx_p">Initially, a neuron is in stage ”Relaxing” which is the ground state of its operation.
(We also introduce a ”Sleeping” or ”Standby” helper stage, which can be imagined
as a low-power mode in electronical or state maintenance mode of biological computing; or ”creating the neuron” in biology; a ”no payload activity” stage.) The stage transition from ”Sleeping” also <span class="ltx_text ltx_font_italic">resets the internal stage variable</span> membrane potential (to the value of the resting potential).
In biology, a ”leaking” background activity takes place: it changes (among others) the stage variable towards the system’s ”no activity” value.</p>
</div>
<figure id="fig:NeuronStateMachine" class="ltx_figure"><object type="image/svg+xml" data="fig/NeuronStateMachineSimple.svg" id="Ch1.F1.g1" class="ltx_graphics ltx_img_square" width="389" height="381"></object>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1.1: </span>The model of neuron as an abstract state machine</figcaption>
</figure>
<div id="p4" class="ltx_para">
<p class="ltx_p">An event (in form of a pulse of slow ions) arriving from the environment acts as a ”look at me” signal

and the system passes to ”Computing” stage: an excitation begins.
The external signal
acts as triggering a stage change and, simultaneously, contributes to the value of the internal stage variable (membrane voltage).
During normal operation, when the stage variable reaches the critial value (the threshold potential),
the system generates an event: passes to stage ”Delivering” and ”flushes” the collected charge.
In that stage, it starts to deliver a signal toward the environment
(to the other neurons connected to its axon) and after a fixed period, passes to stage ”Relaxing”,
without resetting the stage variable. From this event on, it is again in stage
”Relaxing”, where the ”leaking” and the input pulses from the upstream neurons contribute to its
stage variable. Process ”Delivering” operates an independent subsystem (”Firing”): happens simultaneously with
process of ”Relaxing” which, after some time, usually passes to the next ”Computing”.
Notice that <span class="ltx_text ltx_font_bold ltx_font_italic">the stages ”Computing” and ”Delivering” mutually block
each other and the I/O operations happen in parallel with them</span>. They have temporal lengths, and they must follow in the well-defined order (a ”proper sequencing”) ”Computing”<math id="p4.m1" class="ltx_Math" alttext="\Rightarrow" display="inline"><mo stretchy="false">⇒</mo></math> ”Delivering”<math id="p4.m2" class="ltx_Math" alttext="\Rightarrow" display="inline"><mo stretchy="false">⇒</mo></math>”Relaxing” Theoretically, <span class="ltx_text ltx_font_italic">a three-state system is needed to define the direction of time</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../sec_Single-ImplicationsComputing/ch_Physics/sec_Physics-Spatiotemporal/ch_Physiology/sec_Physiology-Fallacies/sec_Physiology-FallaciesAPThresholds/ch_Computing/sec_Computing-ActionPotential/ch_Information/ch_Multiple/ch_Intelligence/sec_Information-Cognition/ch_Simulation/GTKWave_Simulator/bib.html#bib41" title="" class="ltx_ref">41</a>]</cite>; a fundamental issue for quantum-based computing. In electronical computing we can introduce this as ”up” edge and ”down” edge, with a ”hold” stage between. In electronical computing we can introduce this as ”up” edge and ”down” edge, with a ”hold” stage between. A charge-up process must always happen before discharging. Stage ”Delivering” has a fixed period, stage ”Computing” has a variable period (depends mainly on the upstream neurons), and the total length of the computing period equals their sum. The (physiologically defined) length of the ”Delivering” period limits neuron’s firing rate; the length of ”Computing” is usually much shorter. In any stage, a ”leaking current” changing the stage variable is present; <span class="ltx_text ltx_font_bold ltx_font_italic">the continuous change (the presence of a voltage gradient) has a fundamental importance for a biological computing system</span>.
This current is proportional to the stage variable (membrane current); it is <span class="ltx_text ltx_font_bold ltx_font_italic">not</span> identical with the fixed-size ”leaking current” assumed in the Hodgkin-Huxley model <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../sec_Single-ImplicationsComputing/ch_Physics/sec_Physics-Spatiotemporal/ch_Physiology/sec_Physiology-Fallacies/sec_Physiology-FallaciesAPThresholds/ch_Computing/sec_Computing-ActionPotential/ch_Information/ch_Multiple/ch_Intelligence/sec_Information-Cognition/ch_Simulation/GTKWave_Simulator/bib.html#bib12" title="" class="ltx_ref">12</a>]</cite>.
The event which is issued when stage ”Computing” ends and ”Delivering” begins, separates two physically different operating modes: inputting payload signals for computing
and inputting ”servo” ions for transmitting
(signal transmission to fellow neurons begins and happens in parallel
with further computation(s)).</p>
</div>
<div id="p5" class="ltx_para">
<p class="ltx_p">There are two more possible stage transitions from the stage ”Computing”.
First, the stage variable (due to ”leaking”) may approach its initial value (the resting potential) and the system passes to stage ”Relaxing”; in this case we consider that the excitation ”Failed”.
This happens when leaking is more intense than the input current pulses (the input firing rate is too low or a random firing event started the computing).
Second, an external pulse may have the effect to force the system (independently from the value of the stage variable) to pass instantly to stage ”Delivering”, and after that, to ”Relaxing”. (When several neurons share that input signal,
they will go to ”Relaxing” at the same time: they get synchronized; a simple way of synchronizing low-precision asynchronous oscillators.)</p>
</div>
<div id="p6" class="ltx_para">
<p class="ltx_p">Anyhow: a neuron operates in cooperation with in its environment (the fellow neurons, with outputs distributed in space and time).
It receives multiple inputs at different times (at different offset times from the different upstream neurons) and in different stages.
In stage ”Computing”, the synaptic inputs are open, while
in stage ”Delivering”, the synaptic inputs are closed (the input is ineffective).
It produces multiple outputs (in the sense that the signal may branch along its path), in form of a signal with temporal course.</p>
</div>
<section id="sec:Single-ConceptualOperation" class="ltx_subsubsection">
<h2 class="ltx_title ltx_title_subsubsection">Conceptual operation</h2>

<div id="SSSx1.p1" class="ltx_para">
<p class="ltx_p">With reference to Fig. <a href="../../Single-Overview/sec_Single-Actions/index.html#fig:AP_Conceptual" title="Figure 1.5 ‣ Action Potential (AP) ‣ § 1.4.5 The actions ‣ § 1.4 Overview of the play ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.5</span></a>, we subdivide neuron’s operation
to three stages (green, red, and blue sections of the broken diagram line), in line with the state machine in Fig. <a href="#fig:NeuronStateMachine" title="Figure 1.1 ‣ § 1.3.6 Stages and processes ‣ § 1.3 Abstract modeling ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.1</span></a>.
We start in stage ’Relaxing’ (it is a steady-state,
with the membrane’s voltage at its resting value). Everything is balanced,
the synaptic inputs are enabled.
No currents flow (neither input nor output), since all component have the same potential, there is no driving force for an output current.</p>
</div>
<div id="SSSx1.p2" class="ltx_para">
<p class="ltx_p">The neuron has a stage variable (the membrane potential) and a regulatory
threshold value. There exists a threshold for <span class="ltx_text ltx_font_italic">voltage gradient</span> instead of the <span class="ltx_text ltx_font_italic">membrane’s voltage</span> itself
(the voltage gradient provides a ’driving force’).

As we detail in section <a href="../../sec_Single-ImplicationsComputing/ch_Physics/sec_Physics-MembranesChannels/sec_Demon-in-the-membrane/index.html#sec:Electrodiffusion_VoltageSensing" title="Voltage sensing ‣ § 2.6.2 Demon in the membrane ‣ § 2.6 Membranes and channels ‣ Chapter 2 Physics for neurons ‣ § 1.5 Implications for computing ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.6.2</span></a>, the voltage sensing is based on voltage gradient sensing, which phenomenon correlates with the value of membrane’s voltage.
Given that physiological measurements (such as <a href="../../sec_Single-ImplicationsComputing/ch_Physics/sec_Physics-Electricity/sec_PHYSICS_lamping/index.html#voltage-clamping" title="The very common measuring method reveals some fundamental differences between the electric behavior of conductors and living matter. ”The reason for voltage-clamping ‣ § 2.3.7 Voltage/current clamping/patching ‣ § 2.3 Ions’ electricity ‣ Chapter 2 Physics for neurons ‣ § 1.5 Implications for computing ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0" class="ltx_ref">clamping</a>) suppress the gradient, and only the voltage is measured in a
’freezed’ state, this difference has remained hidden. Crossing the membrane’s voltage threshold value upward and downward causes a
stage transition from ”Computing” to ”Delivering” and from ”Delivering”
to ”Relaxing”, respectively. Another role of that regulatory value is
to open/close the input synapses. Furthermore, when the value exceeds
the threshold, an intense current starts to charge up the condenser,
that later discharges.
We show that, although the change correlates with the value
of membrane’s voltage, the neuron’s membrane actually senses the voltage gradient.</p>
</div>
<div id="SSSx1.p3" class="ltx_para">
<p class="ltx_p">Given that the neuron’s operation resembles
an <math id="SSSx1.p3.m1" class="ltx_Math" alttext="RC" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mi>C</mi></mrow></math> oscillator, the capacitive current of the condenser
changes its direction, leading to changing the potential relative
to the charge-up potential value to a value of opposite sign.
The time constant of the <math id="SSSx1.p3.m2" class="ltx_Math" alttext="RC" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mi>C</mi></mrow></math> oscillator
is set so that the rushed-in current generates a nearly critically damped
oscillation (with a damping parameter about <math id="SSSx1.p3.m3" class="ltx_Math" alttext="\zeta=0.35" display="inline"><mrow><mi>ζ</mi><mo>=</mo><mn>0.35</mn></mrow></math>).</p>
</div>
<div id="SSSx1.p4" class="ltx_para">
<p class="ltx_p">Notice that all these processes happen with well-defined speeds,
i.e., the different stages have well-defined temporal lengths. The length of period ”Delivering” is fixed (defined by physiological parameters),
the length of ”Computing” depends on the activity of the upstream
neurons (furthermore, on the gating due to the membrane’s voltage).
Due to the finite speed, we discuss all operations in

neuron’s own ”local time”.</p>
</div>
<div id="SSSx1.p5" class="ltx_para">
<p class="ltx_p">When the membrane’s voltage decreases below the threshold value,
the axonal inputs are re-opened, that may mean an instant passing
to stage ”Computing” again.
The current stops only when the charge on the membrane disappears (the driving force terminates),
so the current may change continuously, changing the voltage on the
circuit’s output.
The time of the end of operation is ill-defined, and so is the
value of the membrane’s voltage at the time when the next axonal input arrives. <span class="ltx_text ltx_font_italic">The residual potential acts as a (time-dependent) memory</span>,
with about a <math id="SSSx1.p5.m1" class="ltx_Math" alttext="msec" display="inline"><mrow><mi>m</mi><mo>⁢</mo><mi>s</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>c</mi></mrow></math> lifetime; see Fig. <a href="../../Single-Overview/sec_Single-Actions/index.html#fig:AP_Conceptual" title="Figure 1.5 ‣ Action Potential (AP) ‣ § 1.4.5 The actions ‣ § 1.4 Overview of the play ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.5</span></a>.</p>
</div>
</section>
<section id="sec:Single-OperationComputingStages" class="ltx_subsubsection">
<h2 class="ltx_title ltx_title_subsubsection">Stages</h2>

<section id="sec:Single-OperationComputing" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Stage ’Computing’</h3>

<div id="SSSx2.Px1.p1" class="ltx_para">
<p class="ltx_p">The neuron receives its inputs as ’Axonal inputs’. For the first input in stage ’Relaxing’,
the neuron enters stage ’Computing’.
The time of this event is the base time used for calculating the neuron’s ”local time”.

Notice that producing the result is a cooperation
between the neuron and its upstream neurons (the neuron gates its input currents). One of the upstream neurons
opens computing, and the receiving neuron terminates it.</p>
</div>
<div id="SSSx2.Px1.p2" class="ltx_para">
<p class="ltx_p">The physical implementation is
a step-like current gradient which evokes a voltage gradient <math id="SSSx2.Px1.p2.m1" class="ltx_Math" alttext="dV/dt" display="inline"><mrow><mrow><mrow><mi>d</mi><mo>⁢</mo><mi>V</mi></mrow><mo>/</mo><mi>d</mi></mrow><mo>⁢</mo><mi>t</mi></mrow></math>
on the membrane in its intracellular segment, see section <a href="../../Single-Overview/sec_Single-Actions/index.html#subsec:Single-PSP" title="Post-synaptic potentials (PSP) ‣ § 1.4.5 The actions ‣ § 1.4 Overview of the play ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.4.5</span></a>.

The membrane is connected to the axon through a resistor
AIS
(these components, switched in serial, constitute the neuronal oscillator).
Given that the current creates a potential gradient on the membrane, the
increased potential starts a current (”Leaking”) proportional to the voltage difference
between the membrane and the axon (across the AIS). This current decreases
the membrane’s potential (discharges the condenser). In lack of further
excitation, the membrane’s potential decreases back to its resting value
and the neuron returns to stage ’Relaxing’.</p>
</div>
<div id="SSSx2.Px1.p3" class="ltx_para">
<p class="ltx_p">However, for repeated excitation, when the next ’Axonal input’ arrive(s) before
the neuron returns to stage ’Relaxing’, the voltage increases further, and it might reach
a threshold voltage. In such a case, the neuron enters stage ’Delivering’
(the red section of the broken diagram line). The time at which point this happens
depends on the arrival of spikes and the discharge of the membrane (when the
difference of the received charge and the loss due to discharge evokes
a sufficiently large voltage on the condenser’s capacity). At that point,
the computation is finished. <span class="ltx_text ltx_font_italic">The result of the computation is
the time</span> passed between receiving the first ’Axonal input’ and the time when
the neuron closes its input sources (and simultaneously, opens the ion channels
in its wall, see below, to enter stage ”Delivering”). No more input shall be received, so
the neuron disables its synaptic inputs, and prepares for delivering
the result of its ’computation’ (nothing shall be stored: the result is the time of sending the message, but the delivery period takes time; is a fixed-length
process, will follow immediately).</p>
</div>
<div id="SSSx2.Px1.p4" class="ltx_para">
<p class="ltx_p">In this stage, the role of the slow speed is not evident. The current
arrives through an axon, passes the terminal and arrives at the AIS;
the time components cannot be separated.</p>
</div>
</section>
<section id="sec:Single-OperationDelivering" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Stage ’Delivering’</h3>

<div id="SSSx2.Px2.p1" class="ltx_para">
<p class="ltx_p">In this stage,
the result is ready: the time between the arrival of the first
synaptic input and reaching the membrane’s threshold voltage is measured.
No more input is desirable, so the neuron closes its input synapses.
Simultanously, the neuron starts it ”servo” mechanism: it opens its ion channels
and an intense ion current starts to charge the membrane.
It is an ’instant’ current.
The voltage on the membrane quickly rises, and it takes a short time
until its peak voltage reached.
Given that the charge-up current is instant and the increased
membrane voltage drives an outward current, the membrane voltage
gradually decays.
When the voltage drops below the threshold voltage, the neuron re-opens its synaptic inputs and passes to stage ”Relaxing”: it is ready for the next operation. The signal transmission to downstream neurons
happens in parallel with the recent ”Delivering” stage and
the next ”Relaxing” and maybe ”Computing” stages.</p>
</div>
<div id="SSSx2.Px2.p2" class="ltx_para">
<p class="ltx_p">Delivering the result needs huge power because of the noisy environment and
the huge distances, so at the beginning of the ’Delivery’ phase,
the neuron switches in a ’servo’ mechanism. Exceeding the threshold voltage
(either as a consequence of the ’spatiotemporal’ summing several spikes or a single spike with sufficiently large voltage gradient <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../sec_Single-ImplicationsComputing/ch_Physics/sec_Physics-Spatiotemporal/ch_Physiology/sec_Physiology-Fallacies/sec_Physiology-FallaciesAPThresholds/ch_Computing/sec_Computing-ActionPotential/ch_Information/ch_Multiple/ch_Intelligence/sec_Information-Cognition/ch_Simulation/GTKWave_Simulator/bib.html#bib42" title="" class="ltx_ref">42</a>]</cite>) opens the voltage-gated ion channels in the membrane’s wall.
Due to the
vast voltage gradient across the two segments of the membrane, an enormous
amount of ions rush-in into the intracellular space and the intense current
increases the membrane’s potential; for the details see section <a href="../../sec_Single-ImplicationsComputing/ch_Physics/sec_Physics-Electricity/index.html" title="§ 2.3 Ions’ electricity ‣ Chapter 2 Physics for neurons ‣ § 1.5 Implications for computing ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>. The amount of the rushed-in ions
is several times more than those received during the stage ’Computing’.</p>
</div>
<div id="SSSx2.Px2.p3" class="ltx_para">
<p class="ltx_p">The ion channels on all over the surface of the neuron open
at the same time, and they are open only for a very short period
(actually, they implement a sudden ”step current”). However, this
current on the surface is created at different distances from the AIS
and (due to the final speed of the ions) and the time until the ions
arrive at the AIS depends on the distance to AIS.
Due to this effect, the current quickly increases;
until it reaches a maximum.
The time when the AP reaches maximum value (due to the event that
the current from the most distant places of the membrane could reach AIS),
and from this point it starts to decrease.
(there is no other special threshold voltage value:
the charge from the rush-in current distributes on the surface;
the current injection can charge the fixed capacity
membrane to that voltage).
At this point the neuronal condenser is maximally depolarized.
</p>
</div>
<div id="SSSx2.Px2.p4" class="ltx_para">
<p class="ltx_p">The neuronal condenser is loaded to its maximum, and the resistor (the AIS)
enables a current to flow out, so the condenser (the membrane) discharges (repolarizes).
Here enters into the picture that the neuron is resemblant to a serial oscillator.
The condenser stores the charge for some period, and releases it to the AIS
at a later time. As a result, the direction of the current on the neuron’s
membrane reverses, see the shape of the output voltage in table <a href="../../sec_Single-ImplicationsComputing/ch_Physics/sec_Physics-Components/sec_PHYSICS_MEASURINGOSCILLATOR/index.html#RCDifferentiatorCircuit" title="Table 2.2 ‣ § 2.7.7 Oscillator ‣ § 2.7 Neuronal components ‣ Chapter 2 Physics for neurons ‣ § 1.5 Implications for computing ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>.
The essential difference between the serial and parallel <math id="SSSx2.Px2.p4.m1" class="ltx_Math" alttext="RC" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mi>C</mi></mrow></math> oscillators is
that the differentiator circuit can produce opposite voltage on its output
without assuming any additional mechanism, such as an outward current,
given that <span class="ltx_text ltx_font_italic">a current pulse has rising and falling edges which can natively produce
positive and negative voltage derivatives</span>.
As the result of the process, the potential reaching the AIS goes to negative;
a phenomenon called hyperpolarization.
</p>
</div>
<div id="SSSx2.Px2.p5" class="ltx_para">
<p class="ltx_p">Notice that the current in the red section (plus also in the blue section)
of the diagram line still originates from the rushed-in charge. The observer
sees the sum of the resistive and capacitive currents;
maybe new axonal inputs superimposed.</p>
</div>
<div id="SSSx2.Px2.p6" class="ltx_para">
<p class="ltx_p">The ion current’s finite speed plays again. When the axonal arbors re-open,
the ion flows into the membrane at some distant point, so its effect
will be observed some time later; apparently when the neuron membrane is
about its hyperpolarized state.</p>
</div>
</section>
<section id="sec:Single-OperationRelaxing" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Stage ’Relaxing’</h3>

<div id="SSSx2.Px3.p1" class="ltx_para">
<p class="ltx_p">In this stage,
the neuron re-opens its synaptic gates. Recall that the ion channels
used for generating an intense membrane current
are already closed. The neuron passes to stage ’Relaxing’ and is ready for a new computation:
the previous result is under delivering (parallelly, independently),
the axonal inputs are open again.
However, the membrane’s potential at this point may differ from the
resting potential. A new computation begins
(the neuron passes to the stage ”Computing”)
when a new axonal input arrives. Given that the computation is analog, a current flows through the AIS, and the result is the length of the period to reach
the threshold value, the
membrane voltage plays the role of an accumulator (with a time-dependent content): a non-zero initial value acts as a short-time memory in the next computing cycle.
The local time is reset when a new computating cycle begins, but not when eventually the resting potential reached.
</p>
</div>
<div id="SSSx2.Px3.p2" class="ltx_para">
<p class="ltx_p">As the membrane’s voltage drops below the threshold voltage,
the neuron re-opens its synaptic gates (the ion channels in the membrane’s wall
are already closed). The neuron passes to stage ’Relaxing’ and is ready for a new computation:
the previous result is under delivering (parallelly, independently),
the axonal inputs are open again.
However, the membrane’s potential at this point may differ from the
resting potential. Given that the computation is analog, the
membrane voltage plays the role of an accumulator (with a time-dependent content,
given that the current flows though the AIS). A new computation begins
(the neuron passes to the stage ”Computing”)
when a new axonal input arrives. Given that the result is the time to reach
the threshold value, the non-zero initial value acts as a short-time memory.</p>
</div>
<div id="SSSx2.Px3.p3" class="ltx_para">
<p class="ltx_p">The ion current’s finite speed plays again. When the axonal arbors re-open,
the ion flows into the membrane at some distant point, so its effect
will be observed some time later; apparently when the neuron membrane is
about its hyperpolarized state.</p>
</div>
</section>
<section id="sec:Single-OperationClassicStages" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Classic stages</h3>

<div id="SSSx2.Px4.p1" class="ltx_para">
<p class="ltx_p">We can map our ’modern’ stages to those ’classic’ stages and we can see
why defining the length of the Action Potential
is problematic.
The effect of slow current affects the apparent boundary between our
”Delivering” stage and ”Relaxing” stages.
Classical physiology sees the difference and distinguishes ’absolute’ and
’relative’ refractory periods with a smeared boundary between. Furthermore,
it defines the length of the spike with some characteristic point,
such as reaching the resting value for the first or second time, or
reaching the maximum polarization/hyperpolarization. Our derivation of the stages (see Fig. <a href="../../Single-Overview/sec_Single-Actions/index.html#fig:AP_Conceptual" title="Figure 1.5 ‣ Action Potential (AP) ‣ § 1.4.5 The actions ‣ § 1.4 Overview of the play ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.5</span></a>) defines clear-cut breakpoints between them.</p>
</div>
<div id="SSSx2.Px4.p2" class="ltx_para">
<p class="ltx_p">We can define the length of the spike as the sum of the variable-size length of periods ”Computing” and fixed-size period ”Delivering”. The ”absolute refractory”
period is defined as the period while the neuron membrane’s voltage keeps
the gates of the synaptic inputs closed (the value of membrane voltage is above their threshold). That period is apparently extended
(and interpreted as a ”relative refractory” period)
by the period when although the gating is re-enabled, but the slow current did not
yet arrive to the
AIS
where it contributes to the measured
AP, see Fig. <a href="../../Single-Overview/sec_Single-Actions/index.html#fig:AP_Conceptual" title="Figure 1.5 ‣ Action Potential (AP) ‣ § 1.4.5 The actions ‣ § 1.4 Overview of the play ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.5</span></a>. <span class="ltx_text ltx_font_italic">Only one refractory period exists,
plus the effect of the slow current.</span>
</p>
</div>
</section>
<section id="sec:Single_AP_Synaptic" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Synaptic control</h3>

<div id="SSSx2.Px5.p1" class="ltx_para">
<p class="ltx_p">As discussed, controling the operation of its synapses is a
fundamental part of neuronal operation. It is
a kind of gating and implements an ’autonomous cooperation’ with
the upstream neurons. The neuron’s gating uses
a ’downhill method’ for gating: while the membrane’s potential
is above of that of the axonal arbor, the charges cannot enter the membrane.
As soon as the membrane’s voltage exceeds the threshold voltage, the synaptic inputs stop, and restart only when the voltage drops below of that threshold.
The synaptic gating makes interpreting neural information and entropy, as we discuss it in <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../sec_Single-ImplicationsComputing/ch_Physics/sec_Physics-Spatiotemporal/ch_Physiology/sec_Physiology-Fallacies/sec_Physiology-FallaciesAPThresholds/ch_Computing/sec_Computing-ActionPotential/ch_Information/ch_Multiple/ch_Intelligence/sec_Information-Cognition/ch_Simulation/GTKWave_Simulator/bib.html#bib29" title="" class="ltx_ref">29</a>]</cite> and chapter <a href="../../sec_Single-ImplicationsComputing/ch_Physics/sec_Physics-Spatiotemporal/ch_Physiology/sec_Physiology-Fallacies/sec_Physiology-FallaciesAPThresholds/ch_Computing/sec_Computing-ActionPotential/ch_Information/index.html" title="Chapter 5 Neural information ‣ § 4.7 Action Potential ‣ Chapter 4 Neural computing ‣ § 3.7.9 Thresholds of initiating AP ‣ § 3.7 Fallacies ‣ Chapter 3 Abstract neurophysiology ‣ § 2.9 Spatiotemporal ‣ Chapter 2 Physics for neurons ‣ § 1.5 Implications for computing ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, at least hard.



</p>
</div>
</section>
</section>
<section id="sec:Single_AP_Processes" class="ltx_subsubsection">
<h2 class="ltx_title ltx_title_subsubsection">Processes</h2>

<section id="sec:Single-OperationInformation" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Delivering information</h3>

<div id="SSSx3.Px1.p1" class="ltx_para">
<p class="ltx_p">As follows from our interpretation, the appearance of a huge voltage gradient
(evoked by the sudden rush-in current) represents the output
information the neuron delivers, and also the input information
it receives from its upstream neurons through its synapses.

Given that the input currents delivered by the spikes
are gated by the neuron, the information that can be
accounted in the computation must be in the front side of spikes. (The back side is mainly needed for restoring the resting potential.)</p>
</div>
<div id="SSSx3.Px1.p2" class="ltx_para">
<p class="ltx_p">The front side (in the form of a sudden step in the value of the voltage gradient) delivers an extremely precise timing information about at what time the rush-in event in the sender happened, explaining the half-understood experience <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../sec_Single-ImplicationsComputing/ch_Physics/sec_Physics-Spatiotemporal/ch_Physiology/sec_Physiology-Fallacies/sec_Physiology-FallaciesAPThresholds/ch_Computing/sec_Computing-ActionPotential/ch_Information/ch_Multiple/ch_Intelligence/sec_Information-Cognition/ch_Simulation/GTKWave_Simulator/bib.html#bib43" title="" class="ltx_ref">43</a>]</cite> why
”the timing of spikes is important with a
precision roughly two orders of magnitude greater than the temporal
dynamics of the stimulus”. If exceeding the threshold
is the consequence of the charge arriving from a single
upstream neuron, the neuron simply transmits the timing information it received. If several smaller gradients
are summed (and recall that the component gradients decay with
time after their arrival) for reaching the gradient,
then their information content is weighted.</p>
</div>
</section>
<section id="sec:Single-OperationSynchronization" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Synchronization</h3>

<div id="SSSx3.Px2.p1" class="ltx_para">
<p class="ltx_p">Given that the voltage gradient is the pace of temporal change,
a faster rush-in current in the upstream neuron (seen as
a steeper slope <cite class="ltx_cite ltx_citemacro_cite">[<a href="../../sec_Single-ImplicationsComputing/ch_Physics/sec_Physics-Spatiotemporal/ch_Physiology/sec_Physiology-Fallacies/sec_Physiology-FallaciesAPThresholds/ch_Computing/sec_Computing-ActionPotential/ch_Information/ch_Multiple/ch_Intelligence/sec_Information-Cognition/ch_Simulation/GTKWave_Simulator/bib.html#bib42" title="" class="ltx_ref">42</a>]</cite>)
can evoke firing, independently from the membrane’s voltage. 
This observation, alone, underpins
that exceeding a <span class="ltx_text ltx_font_italic">voltage gradient threshold</span> (instead of
a <span class="ltx_text ltx_font_italic">voltage threshold</span>)
leads to firing.
Receiving a synchrony signal does not set the ”local time”

to zero; instead, it forces an instant firing. After firing,
the first synaptic input sets the time base as we have discussed it above.</p>
</div>
<div id="SSSx3.Px2.p2" class="ltx_para">
<p class="ltx_p">It is interesting to note that, according to Shannon,


a single spike does not carry information, given that the shape of the spikes are identical, only its time can deliver information. And, yet,
a single spike can carry the information that a new collective operation (of neurassemblies) begins and the participating neuron’s operation must synchronize their ”local time” to a remote basetime. In the sense of time-space, the signal resets the time base of all receiver neurons to zero. That is, all their synchronized upstream neurons will reset their timebase to that synchrony signal. Consequently, the neuron will receive its input spikes on a relatively well-defined scale, despite that the sender neurons send their spikes at different absolute times; by automatically ”calculating” and applying
the needed offset time.
The neuron’s frequency stability is low, so the synchrony signal (the base frequencies) must be repeated relatively frequently for the system’s stable operation.
Of course, the neuron does not know the absolute time.



The local time’s starting time <math id="SSSx3.Px2.p2.m1" class="ltx_Math" alttext="t_{o}" display="inline"><msub><mi>t</mi><mi>o</mi></msub></math>
is the time when the first synaptic input arrives and its range of interpretation ends when a new computation starts or when
the membrane’s potential goes back to its resting value.</p>
</div>
</section>
<section id="sec:Single-OperationLearning" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Learning</h3>

<div id="SSSx3.Px3.p1" class="ltx_para">
<p class="ltx_p">It might also happen that (also depending on the residual
membrane voltage) the outgoing spike’s delivering begins
immediately after last spike arrives.
Given that the rising edge delivers the important timing information, and the voltage gradients contributions
received before the last spike somewhat faded in the meantime,
one can understand Hebb’s observation in terms of learning: the last spike (before firing) contributes more than the ones
received earlier.
</p>
</div>
</section>
</section>
</section>
</div>
<footer class="ltx_page_footer">
<div class="ltx_align_center">
<a href="../sec_SINGLE_ExistingModels/index.html" title="In § 1.3 Abstract modeling ‣ Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0" class="ltx_ref" rel="prev"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.3.5 </span>Existing models</span></a><a href="../../Single-Overview/index.html" title="In Chapter 1 Single neurons ‣ Quick Start ‣ Foreword ‣ Dynamic Abstract Neural Computing with Electronic Simulation (DANCES) Version 0.1.0" class="ltx_ref" rel="next"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.4 </span>Overview</span></a>
</div>
<div class="ltx_page_logo">Generated  on Fri May 23 09:01:16 2025 by <a href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>
</body>
</html>
